{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 時間目\n",
    "# フィルタを使って学習機械を作ってみよう（続き）\n",
    "\n",
    "それでは，畳込みニューラルネットワークを，多段化して深層畳み込みニューラルネットワーク (Deep Convolution Neural Network) を実現してみましょう．\n",
    "\n",
    "基本的には `model` の部分を繰り返すという話になります．\n",
    "前の時間のものは *初期視覚野* のモデルとして畳み込みネットワークを作りいましたが，高次視覚野をモデル化させるために\n",
    "初期視覚野と同じような構造を用意してやるだけです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# とりあえずはおまじない\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを用意する．\n",
    "\n",
    "データは先程と同じく MNIST を用います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train_label), (x_test, y_test_label) = mnist.load_data()\n",
    "\n",
    "# このままだと扱いにくいので画像データは [0, 1] の値を持つデータにします．\n",
    "x_train = x_train.astype('float32').reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.astype('float32').reshape(10000, 28, 28, 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# ラベルデータもちょっと扱いにくいので 10 要素のベクトルで表す (one-hot vector 表現)\n",
    "y_train = keras.utils.to_categorical(y_train_label)\n",
    "y_test = keras.utils.to_categorical(y_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覚モデルを構築してみる．\n",
    "\n",
    "高次視覚野のモデルとしては，初期視覚野的のモデルを繰り返し適用することで作り出します．\n",
    "あまり大規模なものにすると計算時間がかかるので，ここでは，初期視覚野の構造を2回繰り返すことを考えます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 初期視覚野の部分は前述の model と同じ\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# 高次視覚野は上記の初期視覚野の部分を繰り返し作る\n",
    "model.add(Conv2D(16, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで，高次視覚野のモデルになっていると思うことにしましょう．\n",
    "この表現を分類器にかけてみるのは，前のモデルと一緒です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類器，とりあえずはおまじないと思っておｋ\n",
    "\n",
    "model.add(Flatten()) # 上記表現を1列のベクトルに並べて\n",
    "model.add(Dense(10, activation='softmax')) # 識別器を構成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習\n",
    "\n",
    "さて，ここまででモデルができました．でもフィルタの係数とかは決まってません．この部分を学習で決めることにします．\n",
    "学習自体は，ある種の関数(loss関数と呼ばれます)を小さくすることで求めます．\n",
    "ここでは `categorical_crossentropy` と呼ばれるを loss 関数としています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# 学習モデルを定義して\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# 学習させます\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss の値\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('loss value')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "# 学習データに対する正答率\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Accuracy (For training set)')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大体同程度の識別精度になっていることがわかると思われます．\n",
    "次にテストセットで評価してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストセットで評価してみる\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('test loss: ', score[0])\n",
    "print('test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おおよそ 98 % 程度の精度（が出るはず）であるので，まぁまぁのものができた．\n",
    "\n",
    "ついでに，間違えたやつをピックアップしてみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 識別間違いしたやつをピックアップしてみる\n",
    "y_pred_label = model.predict_classes(x_test)\n",
    "\n",
    "idx = (y_pred_label != y_test_label) # 答えが違う添字のやつを抜き出し\n",
    "x_failed = x_test[idx]\n",
    "y_true_failed = y_test_label[idx]\n",
    "y_pred_failed = y_pred_label[idx]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(x_failed[i, :, :, 0], cmap='gray')\n",
    "    plt.title('True: %d, Pred: %d' % (y_true_failed[i], y_pred_failed[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
